apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: german-energy-
spec:
  entrypoint: german-energy
  templates:
  - name: german-energy
    dag:
      tasks:
      - name: get-clean
        template: get-clean

      - name: post-germanyenergy
        dependencies: [get-clean]
        template: post-germanyenergy

  - name: get-clean
    script:
      image: gcr.io/kdcc-282418/python-worker
      command: [python]
      source: |
          from wfunc.depower import depower
          from wfunc import downloader
  


          urls = {'conventional_plants.csv':'https://data.open-power-system-data.org/conventional_power_plants/2018-12-20/conventional_power_plants_DE.csv',
          'german_polgon.json':'https://raw.githubusercontent.com/isellsoap/deutschlandGeoJSON/master/4_kreise/2_hoch.geo.json'}
          bucket = 'workflow'
          downloader.get(bucket,urls)
          dfc = depower.fill_missing_data(list(urls)[0])
          de = depower.powersetter(dfc, list(urls)[1])
          downloader.save_minio(bucket, 'output.geojson')

  - name: post-germanyenergy
    script:
      image: gcr.io/kdcc-282418/jup
      env:
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: aws-secret-config
              key: access_key
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: aws-secret-config
              key: key_id
      command: [python]
      source: |
        # import subprocess
        import boto3
        import nbformat
        from nbconvert import HTMLExporter
        from nbconvert.preprocessors import ExecutePreprocessor
        
        # s3 = boto3.resource('s3')
        # bucket = s3.Bucket('maythamalherz.com')

        # notebook_filename = 'germanyenergy'
        # notebook_ipynb = notebook_filename + '.ipynb'
        # notebook_html = notebook_filename + ".html"
        
        # command = 'jupyter nbconvert --to html --template full ' + 'germanyenergy'
        # process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)
        # output, error = process.communicate()

        # bucket.put_object(Key=notebook_html, Body=notebook_html, ContentType='text/html', ACL= 'public-read' )
        


        def post_notebook(notebook_filename, bucket_name ):
             
            notebook_ipynb = notebook_filename + '.ipynb'
            notebook_html = notebook_filename + ".html"
            # nbconvert --to html --template full
            with open(notebook_ipynb) as f:
                nb = nbformat.read(f, as_version=4)

            ep = ExecutePreprocessor(timeout=600, kernel_name='python3')

            ep.preprocess(nb, {'metadata': {'path': ''}})
 
 
 
 
 
 
 
 
 ########################################################
 
  # - name: get-clean
  #   script:
      
  #     image: gcr.io/kdcc-282418/jup
  #     env:
  #       - name: AWS_SECRET_ACCESS_KEY
  #         valueFrom:
  #           secretKeyRef:
  #             name: aws-secret-config
  #             key: access_key
  #       - name: AWS_ACCESS_KEY_ID
  #         valueFrom:
  #           secretKeyRef:
  #             name: aws-secret-config
  #             key: key_id
  #     command: ["jupyter trust test.ipynb;voila --debug test.ipynb --ExecutePreprocessor.timeout=180 --port 3001; ls -al" ]
  #     source: |
  #         import nbconvert
  #         import boto3


  #         s3 = boto3.resource('s3')
  #         bucket = s3.Bucket('workflowkdcc')
  #         bucket
